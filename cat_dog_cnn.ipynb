{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzCn8-SmiCxC",
        "outputId": "73b8c4b0-ac61-4a37-cae6-79a245092dc8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/cat_dog_data.zip'  # change if inside a folder\n",
        "extract_to = '/content/cat_dog_dataset'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)"
      ],
      "metadata": {
        "id": "CfGy8Ea4mPps"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/cat_dog_dataset/PetImages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJpRK-UYm8rV",
        "outputId": "308b5429-e2e4-40e7-8342-da6c8ff2549a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat  Dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, random\n",
        "\n",
        "base_dir = '/content/cat_dog_dataset'\n",
        "src_dir = os.path.join(base_dir, 'PetImages')\n",
        "\n",
        "# Create target directories\n",
        "sets = ['train', 'validation', 'test']\n",
        "categories = ['cats', 'dogs']\n",
        "\n",
        "for s in sets:\n",
        "    for cat in categories:\n",
        "        os.makedirs(os.path.join(base_dir, s, cat), exist_ok=True)\n",
        "\n",
        "def split_data(category, label):\n",
        "    src_folder = os.path.join(src_dir, category)\n",
        "    images = [img for img in os.listdir(src_folder) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    n = len(images)\n",
        "    train_split = int(0.7 * n)\n",
        "    val_split = int(0.15 * n)\n",
        "\n",
        "    train_imgs = images[:train_split]\n",
        "    val_imgs = images[train_split:train_split + val_split]\n",
        "    test_imgs = images[train_split + val_split:]\n",
        "\n",
        "    for img in train_imgs:\n",
        "        try:\n",
        "            shutil.copy(os.path.join(src_folder, img), os.path.join(base_dir, 'train', label, img))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    for img in val_imgs:\n",
        "        try:\n",
        "            shutil.copy(os.path.join(src_folder, img), os.path.join(base_dir, 'validation', label, img))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    for img in test_imgs:\n",
        "        try:\n",
        "            shutil.copy(os.path.join(src_folder, img), os.path.join(base_dir, 'test', label, img))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# Run for both categories\n",
        "split_data('Cat', 'cats')\n",
        "split_data('Dog', 'dogs')"
      ],
      "metadata": {
        "id": "1Vdqk_jepTYJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/cat_dog_dataset/train'\n",
        "val_dir = '/content/cat_dog_dataset/validation'\n",
        "test_dir = '/content/cat_dog_dataset/test'"
      ],
      "metadata": {
        "id": "gyZUKWzrqVko"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gLCEIZEd3IxJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen= ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "UkPFgfXDxanB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen= train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size= (150, 150),\n",
        "    batch_size= 32,\n",
        "    class_mode= \"binary\"\n",
        ")\n",
        "\n",
        "valid_gen= val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size= (150,150),\n",
        "    batch_size= 32,\n",
        "    class_mode= \"binary\"\n",
        ")\n",
        "\n",
        "test_gen= val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size= (150,150),\n",
        "    batch_size= 32,\n",
        "    class_mode= \"binary\",\n",
        "    shuffle= False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-por0Mb26u3",
        "outputId": "83896039-cbde-471b-e4fa-ced359828759"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17498 images belonging to 2 classes.\n",
            "Found 3748 images belonging to 2 classes.\n",
            "Found 3752 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),  # Extract basic features (edges, corners)\n",
        "    MaxPooling2D(2, 2),  # Downsample to reduce spatial size and computation\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),  # Extract deeper/more complex features\n",
        "    MaxPooling2D(2, 2),  # Further downsampling\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),  # Learn even higher-level features\n",
        "    MaxPooling2D(2, 2),  # Reduce size while keeping important features\n",
        "\n",
        "    Flatten(),  # Convert 3D feature maps to 1D vector for dense layers\n",
        "\n",
        "    Dense(512, activation='relu'),  # Fully connected layer to learn non-linear combinations\n",
        "    Dropout(0.5),  # Prevent overfitting by randomly deactivating 50% neurons\n",
        "\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification (cat or dog)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jhhOKbq4Rw6",
        "outputId": "b286c01f-0487-40b1-96ba-bb3d15eab8d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "j9Vi7S-O_lD8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=10,\n",
        "    validation_data=valid_gen\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khFzXSgq_rdT",
        "outputId": "accde70f-ddd8-4441-c08a-678f2ebd8d3a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1193s\u001b[0m 2s/step - accuracy: 0.5236 - loss: 0.7098 - val_accuracy: 0.5414 - val_loss: 0.6872\n",
            "Epoch 2/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1200s\u001b[0m 2s/step - accuracy: 0.5589 - loss: 0.6800 - val_accuracy: 0.6070 - val_loss: 0.6448\n",
            "Epoch 3/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1156s\u001b[0m 2s/step - accuracy: 0.6080 - loss: 0.6536 - val_accuracy: 0.6966 - val_loss: 0.5939\n",
            "Epoch 4/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1164s\u001b[0m 2s/step - accuracy: 0.6410 - loss: 0.6309 - val_accuracy: 0.7038 - val_loss: 0.5683\n",
            "Epoch 5/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1165s\u001b[0m 2s/step - accuracy: 0.6867 - loss: 0.5861 - val_accuracy: 0.7124 - val_loss: 0.5557\n",
            "Epoch 6/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1166s\u001b[0m 2s/step - accuracy: 0.7091 - loss: 0.5601 - val_accuracy: 0.7372 - val_loss: 0.5458\n",
            "Epoch 7/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1167s\u001b[0m 2s/step - accuracy: 0.7248 - loss: 0.5428 - val_accuracy: 0.7559 - val_loss: 0.5015\n",
            "Epoch 8/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1222s\u001b[0m 2s/step - accuracy: 0.7371 - loss: 0.5275 - val_accuracy: 0.7852 - val_loss: 0.4635\n",
            "Epoch 9/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1160s\u001b[0m 2s/step - accuracy: 0.7429 - loss: 0.5152 - val_accuracy: 0.7980 - val_loss: 0.4486\n",
            "Epoch 10/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1155s\u001b[0m 2s/step - accuracy: 0.7550 - loss: 0.4955 - val_accuracy: 0.7919 - val_loss: 0.4442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/cat_dog_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqAMu5ou_vjk",
        "outputId": "758b34ad-0013-4a02-b802-fc9711c0cb46"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['accuracy']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUt8NpqjwLfv",
        "outputId": "859cb931-4f0e-491b-9847-e59298566c33"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5457195043563843,\n",
              " 0.5723510980606079,\n",
              " 0.6193850636482239,\n",
              " 0.6546462178230286,\n",
              " 0.6876785755157471,\n",
              " 0.7124242782592773,\n",
              " 0.7205395102500916,\n",
              " 0.7393416166305542,\n",
              " 0.7461995482444763,\n",
              " 0.7551148533821106]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2trvVSWNP6yG",
        "outputId": "b5938b02-7a2a-4788-eb8b-4f3f2df918fd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m111/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 519ms/step - accuracy: 0.7632 - loss: 0.5075"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 512ms/step - accuracy: 0.7655 - loss: 0.5035\n",
            "Test Accuracy: 0.7974\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_gen.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGjkoYn0TXeb",
        "outputId": "a47400d6-10f8-4050-c36b-06f9b6c13537"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cats': 0, 'dogs': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Get predictions\n",
        "test_probs = model.predict(test_gen)\n",
        "test_preds = (test_probs > 0.5).astype(int).reshape(-1)\n",
        "true_labels = test_gen.classes\n",
        "class_names = list(test_gen.class_indices.keys())\n",
        "\n",
        "# Metrics\n",
        "print(f\"✅ Test Accuracy: {test_acc:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, test_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, test_preds, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L90TI45BVkiI",
        "outputId": "e38eb1d4-c6a5-453c-d2eb-33f09fab19da"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 505ms/step\n",
            "✅ Test Accuracy: 0.7974\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1409  467]\n",
            " [ 293 1583]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        cats       0.83      0.75      0.79      1876\n",
            "        dogs       0.77      0.84      0.81      1876\n",
            "\n",
            "    accuracy                           0.80      3752\n",
            "   macro avg       0.80      0.80      0.80      3752\n",
            "weighted avg       0.80      0.80      0.80      3752\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJjN6cdFWJhK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}