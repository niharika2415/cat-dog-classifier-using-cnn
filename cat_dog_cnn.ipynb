{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzCn8-SmiCxC",
        "outputId": "14b6594b-012a-43be-88a2-46fbe9bbb2b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/cat_dog_data.zip'  # change if inside a folder\n",
        "extract_to = '/content/cat_dog_dataset'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)"
      ],
      "metadata": {
        "id": "CfGy8Ea4mPps"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/cat_dog_dataset/PetImages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJpRK-UYm8rV",
        "outputId": "3e0fa55c-80e8-4bcf-ab79-30bf3dc365ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat  Dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil, random\n",
        "\n",
        "base_dir = '/content/cat_dog_dataset'\n",
        "src_dir = os.path.join(base_dir, 'PetImages')\n",
        "\n",
        "# Create target directories\n",
        "sets = ['train', 'validation', 'test']\n",
        "categories = ['cats', 'dogs']\n",
        "\n",
        "for s in sets:\n",
        "    for cat in categories:\n",
        "        os.makedirs(os.path.join(base_dir, s, cat), exist_ok=True)\n",
        "\n",
        "def split_data(category, label):\n",
        "    src_folder = os.path.join(src_dir, category)\n",
        "    images = [img for img in os.listdir(src_folder) if img.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    random.shuffle(images)\n",
        "\n",
        "    n = len(images)\n",
        "    train_split = int(0.7 * n)\n",
        "    val_split = int(0.15 * n)\n",
        "\n",
        "    train_imgs = images[:train_split]\n",
        "    val_imgs = images[train_split:train_split + val_split]\n",
        "    test_imgs = images[train_split + val_split:]\n",
        "\n",
        "    for img in train_imgs:\n",
        "        try:\n",
        "            shutil.copy(os.path.join(src_folder, img), os.path.join(base_dir, 'train', label, img))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    for img in val_imgs:\n",
        "        try:\n",
        "            shutil.copy(os.path.join(src_folder, img), os.path.join(base_dir, 'validation', label, img))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    for img in test_imgs:\n",
        "        try:\n",
        "            shutil.copy(os.path.join(src_folder, img), os.path.join(base_dir, 'test', label, img))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# Run for both categories\n",
        "split_data('Cat', 'cats')\n",
        "split_data('Dog', 'dogs')"
      ],
      "metadata": {
        "id": "1Vdqk_jepTYJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/cat_dog_dataset/train'\n",
        "val_dir = '/content/cat_dog_dataset/validation'\n",
        "test_dir = '/content/cat_dog_dataset/test'"
      ],
      "metadata": {
        "id": "gyZUKWzrqVko"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gLCEIZEd3IxJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_test_datagen= ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "UkPFgfXDxanB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen= train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size= (150, 150),\n",
        "    batch_size= 32,\n",
        "    class_mode= \"binary\"\n",
        ")\n",
        "\n",
        "valid_gen= val_test_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size= (150,150),\n",
        "    batch_size= 32,\n",
        "    class_mode= \"binary\"\n",
        ")\n",
        "\n",
        "test_gen= val_test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size= (150,150),\n",
        "    batch_size= 32,\n",
        "    class_mode= \"binary\",\n",
        "    shuffle= False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-por0Mb26u3",
        "outputId": "bdd9eb62-cc12-4c22-e5e8-4eb69447fc7b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17498 images belonging to 2 classes.\n",
            "Found 3748 images belonging to 2 classes.\n",
            "Found 3752 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),  # Extract basic features (edges, corners)\n",
        "    MaxPooling2D(2, 2),  # Downsample to reduce spatial size and computation\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),  # Extract deeper/more complex features\n",
        "    MaxPooling2D(2, 2),  # Further downsampling\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'), # Learn even higher-level features\n",
        "    MaxPooling2D(2, 2),  # Reduce size while keeping important features\n",
        "\n",
        "    Flatten(),  # Convert 3D feature maps to 1D vector for dense layers\n",
        "\n",
        "    Dense(512, activation='relu'),  # Fully connected layer to learn non-linear combinations\n",
        "    Dropout(0.5),  # Prevent overfitting by randomly deactivating 50% neurons\n",
        "\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification (cat or dog)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jhhOKbq4Rw6",
        "outputId": "233ebccf-6f54-4de2-891d-7efa5ce7cf5c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "j9Vi7S-O_lD8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=10,\n",
        "    validation_data=valid_gen\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khFzXSgq_rdT",
        "outputId": "c3a652c7-a977-4983-ce92-793ff263616d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 244ms/step - accuracy: 0.5165 - loss: 0.7588 - val_accuracy: 0.5576 - val_loss: 0.6818\n",
            "Epoch 2/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 237ms/step - accuracy: 0.5726 - loss: 0.6807 - val_accuracy: 0.6321 - val_loss: 0.6495\n",
            "Epoch 3/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 233ms/step - accuracy: 0.6281 - loss: 0.6464 - val_accuracy: 0.6710 - val_loss: 0.5976\n",
            "Epoch 4/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 234ms/step - accuracy: 0.6694 - loss: 0.6127 - val_accuracy: 0.7463 - val_loss: 0.5276\n",
            "Epoch 5/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 232ms/step - accuracy: 0.6996 - loss: 0.5810 - val_accuracy: 0.7385 - val_loss: 0.5181\n",
            "Epoch 6/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 240ms/step - accuracy: 0.7189 - loss: 0.5486 - val_accuracy: 0.7796 - val_loss: 0.4574\n",
            "Epoch 7/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 231ms/step - accuracy: 0.7562 - loss: 0.5108 - val_accuracy: 0.8004 - val_loss: 0.4485\n",
            "Epoch 8/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 234ms/step - accuracy: 0.7651 - loss: 0.4918 - val_accuracy: 0.8164 - val_loss: 0.3872\n",
            "Epoch 9/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 229ms/step - accuracy: 0.7797 - loss: 0.4688 - val_accuracy: 0.8260 - val_loss: 0.3924\n",
            "Epoch 10/10\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 236ms/step - accuracy: 0.7821 - loss: 0.4622 - val_accuracy: 0.8271 - val_loss: 0.3746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/cat_dog_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21IjY_-jaK-H",
        "outputId": "98019ed1-e890-4142-dd23-3e7fada82a7e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.history['accuracy']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUt8NpqjwLfv",
        "outputId": "5aca28b8-4167-41ec-ae8b-93870671b525"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5354897975921631,\n",
              " 0.5877243280410767,\n",
              " 0.641444742679596,\n",
              " 0.6811635494232178,\n",
              " 0.7056235074996948,\n",
              " 0.7273974418640137,\n",
              " 0.7582009434700012,\n",
              " 0.767859160900116,\n",
              " 0.7831752300262451,\n",
              " 0.789747416973114]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2trvVSWNP6yG",
        "outputId": "7f1558de-01d9-42ae-e699-d96835b5ec61"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m114/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8530 - loss: 0.3517"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:950: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - accuracy: 0.8520 - loss: 0.3525\n",
            "Test Accuracy: 0.8300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_gen.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGjkoYn0TXeb",
        "outputId": "a47400d6-10f8-4050-c36b-06f9b6c13537"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cats': 0, 'dogs': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Get predictions\n",
        "test_probs = model.predict(test_gen)\n",
        "test_preds = (test_probs > 0.5).astype(int).reshape(-1)\n",
        "true_labels = test_gen.classes\n",
        "class_names = list(test_gen.class_indices.keys())\n",
        "\n",
        "# Metrics\n",
        "print(f\"✅ Test Accuracy: {test_acc:.4f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(true_labels, test_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, test_preds, target_names=class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L90TI45BVkiI",
        "outputId": "2b0d6d37-fda6-40bf-d900-51a4bf599c78"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step\n",
            "✅ Test Accuracy: 0.8300\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1624  252]\n",
            " [ 386 1490]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        cats       0.81      0.87      0.84      1876\n",
            "        dogs       0.86      0.79      0.82      1876\n",
            "\n",
            "    accuracy                           0.83      3752\n",
            "   macro avg       0.83      0.83      0.83      3752\n",
            "weighted avg       0.83      0.83      0.83      3752\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJjN6cdFWJhK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}